{
 "cells": [
  {
   "cell_type": "raw",
   "id": "547fea82-c2ff-4f6d-8ae6-c4333060070e",
   "metadata": {},
   "source": [
    "So by now, the status is \n",
    "\n",
    "Data Cleaned & Explored:\n",
    "    - no missing values\n",
    "    - Understood skew, outliers & distributions\n",
    "    - checked correlations (.corr() + Cramer's V)\n",
    "\n",
    "Feature Selection done ('is_returned','delivery_delay','payment_value',\n",
    "    'price','customer_state_SP','product_category_bed_bath_table','review_score',)\n",
    "\n",
    "Final Feature & Target Split\n",
    "\n",
    "Verified:\n",
    "\t-No missing values in X\n",
    "\t-Boolean columns correctly typed\n",
    "\t-Shapes and types all consistent\n",
    "\t-Class imbalance identified (will address in modeling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6f283e2-ce10-4936-acfb-fe65c1b7f69c",
   "metadata": {},
   "source": [
    "Day 1 — Model Development & Experiment Tracking\n",
    "\n",
    "Goal: Build ML model + implement MLflow tracking\n",
    "\t•\tPreprocess data: one-hot encoding, fill nulls, scaling\n",
    "\t•\tTrain model: Logistic Regression or XGBoost\n",
    "\t•\tLog metrics, params, artifacts with MLflow\n",
    "\t•\tSave model using mlflow.sklearn.log_model()\n",
    "\t•\tAdd train.py script to run model training (for automation\n",
    "\n",
    "Day 1 (Model Training Plan) - In Day 1, we will:\n",
    "\t1.\tSplit X and y into train/test\n",
    "\t2.\tScale the numeric features\n",
    "\t3.\tTrain a Logistic Regression model (baseline)\n",
    "\t4.\tTrack metrics using MLflow\n",
    "\t5.\tLog hyperparameters, metrics, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716fb7ba-ca53-4b79-b502-432568f19287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and installations\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #for splitting the data\n",
    "from sklearn.preprocessing import StandardScaler #for standardisation\n",
    "from sklearn.linear_model import LogisticRegression #for baseline model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score #for metrics\n",
    "pip install xgboost lightgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595becc6-92aa-4d21-9292-a9006bb01fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "X = pd.read_csv(\"X.csv\") \n",
    "y = pd.read_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7c5ab4-d9ac-4641-bcde-b097d4b4a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test split, Split X and y into train/test\n",
    "\n",
    "#Splitting X and y into train and test sets(80/20), while preserving the class imbalance(ratio of returned, non-retuned) \n",
    "#with stratify as class is imbalanced\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856029b5-79c9-4af2-a01f-a034eb2c974c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delivery_delay                     float64\n",
       "payment_value                      float64\n",
       "price                              float64\n",
       "customer_state_SP                     bool\n",
       "product_category_bed_bath_table       bool\n",
       "review_score                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157a8482-70f5-411e-bbab-9b8fa36cd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are converting boolean to int as its friendly for future pipeline building\n",
    "\n",
    "X_train[['customer_state_SP','product_category_bed_bath_table']] = X_train[['customer_state_SP','product_category_bed_bath_table']].astype(int)\n",
    "X_test[['customer_state_SP','product_category_bed_bath_table']] = X_test[['customer_state_SP','product_category_bed_bath_table']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c734889-ffa4-4144-8798-1ee61faf4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising numerical columns\n",
    "num_cols = ['delivery_delay', 'payment_value', 'price', 'review_score']\n",
    "\n",
    "# Fit and transform on train, transform on test\n",
    "scaler= StandardScaler()\n",
    "X_train[num_cols]=scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols]=scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0683e8-95f8-42d2-8bb6-05dfa393c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Train Baseline Model\n",
    "\n",
    "model= LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1835195-b627-473f-89da-9eecec49865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20450  2569]\n",
      " [   12    96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     23019\n",
      "           1       0.04      0.89      0.07       108\n",
      "\n",
      "    accuracy                           0.89     23127\n",
      "   macro avg       0.52      0.89      0.50     23127\n",
      "weighted avg       0.99      0.89      0.94     23127\n",
      "\n",
      "ROC AUC Score: 0.9277923390178484\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cb0ce8c-7a60-44d6-9b4c-ac1ae81c57c8",
   "metadata": {},
   "source": [
    "What’s working:\n",
    "\t- The model is very good at catching most actual returns (high recall = 89%)\n",
    "\t- ROC AUC is very strong (0.93) → model is able to rank return likelihood well\n",
    "\n",
    "What needs work:\n",
    "\t- Precision is too low (4%) → it’s flagging too many orders as returns, when they’re not\n",
    "\t- May lead to unnecessary actions (like unnecessary refund prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1120789-9709-4415-ba07-82b372bda718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune the classification threshold (Right now, predict() uses default threshold = 0.5\n",
    "# But maybe predicting return only if probability > 0.9 improves precision.)\n",
    "# Set threshold high (e.g., 0.85 to 0.95)\n",
    "threshold = 0.9\n",
    "y_pred_thresh = (y_prob > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b205b9-2f10-4e54-887d-04d08502241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22047   972]\n",
      " [   61    47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     23019\n",
      "           1       0.05      0.44      0.08       108\n",
      "\n",
      "    accuracy                           0.96     23127\n",
      "   macro avg       0.52      0.70      0.53     23127\n",
      "weighted avg       0.99      0.96      0.97     23127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate\n",
    "print(confusion_matrix(y_test, y_pred_thresh))\n",
    "print(classification_report(y_test, y_pred_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c42631f-0f52-4fff-9145-4e64cf631cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am for this  0\n",
      "[[    0 23019]\n",
      " [    0   108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     23019\n",
      "           1       0.00      1.00      0.01       108\n",
      "\n",
      "    accuracy                           0.00     23127\n",
      "   macro avg       0.00      0.50      0.00     23127\n",
      "weighted avg       0.00      0.00      0.00     23127\n",
      "\n",
      "I am for this  0.5\n",
      "[[20450  2569]\n",
      " [   12    96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     23019\n",
      "           1       0.04      0.89      0.07       108\n",
      "\n",
      "    accuracy                           0.89     23127\n",
      "   macro avg       0.52      0.89      0.50     23127\n",
      "weighted avg       0.99      0.89      0.94     23127\n",
      "\n",
      "I am for this  0.1\n",
      "[[13430  9589]\n",
      " [    2   106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.74     23019\n",
      "           1       0.01      0.98      0.02       108\n",
      "\n",
      "    accuracy                           0.59     23127\n",
      "   macro avg       0.51      0.78      0.38     23127\n",
      "weighted avg       1.00      0.59      0.73     23127\n",
      "\n",
      "I am for this  0.15\n",
      "[[15696  7323]\n",
      " [    2   106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81     23019\n",
      "           1       0.01      0.98      0.03       108\n",
      "\n",
      "    accuracy                           0.68     23127\n",
      "   macro avg       0.51      0.83      0.42     23127\n",
      "weighted avg       1.00      0.68      0.81     23127\n",
      "\n",
      "I am for this  0.2\n",
      "[[17090  5929]\n",
      " [    2   106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85     23019\n",
      "           1       0.02      0.98      0.03       108\n",
      "\n",
      "    accuracy                           0.74     23127\n",
      "   macro avg       0.51      0.86      0.44     23127\n",
      "weighted avg       1.00      0.74      0.85     23127\n",
      "\n",
      "I am for this  0.25\n",
      "[[18110  4909]\n",
      " [    2   106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88     23019\n",
      "           1       0.02      0.98      0.04       108\n",
      "\n",
      "    accuracy                           0.79     23127\n",
      "   macro avg       0.51      0.88      0.46     23127\n",
      "weighted avg       1.00      0.79      0.88     23127\n",
      "\n",
      "I am for this  0.3\n",
      "[[18814  4205]\n",
      " [    3   105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90     23019\n",
      "           1       0.02      0.97      0.05       108\n",
      "\n",
      "    accuracy                           0.82     23127\n",
      "   macro avg       0.51      0.89      0.47     23127\n",
      "weighted avg       1.00      0.82      0.90     23127\n",
      "\n",
      "I am for this  0.35\n",
      "[[19376  3643]\n",
      " [    8   100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     23019\n",
      "           1       0.03      0.93      0.05       108\n",
      "\n",
      "    accuracy                           0.84     23127\n",
      "   macro avg       0.51      0.88      0.48     23127\n",
      "weighted avg       1.00      0.84      0.91     23127\n",
      "\n",
      "I am for this  0.4\n",
      "[[19813  3206]\n",
      " [   11    97]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     23019\n",
      "           1       0.03      0.90      0.06       108\n",
      "\n",
      "    accuracy                           0.86     23127\n",
      "   macro avg       0.51      0.88      0.49     23127\n",
      "weighted avg       0.99      0.86      0.92     23127\n",
      "\n",
      "I am for this  0.45\n",
      "[[20157  2862]\n",
      " [   11    97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93     23019\n",
      "           1       0.03      0.90      0.06       108\n",
      "\n",
      "    accuracy                           0.88     23127\n",
      "   macro avg       0.52      0.89      0.50     23127\n",
      "weighted avg       0.99      0.88      0.93     23127\n",
      "\n",
      "I am for this  0.5\n",
      "[[20450  2569]\n",
      " [   12    96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     23019\n",
      "           1       0.04      0.89      0.07       108\n",
      "\n",
      "    accuracy                           0.89     23127\n",
      "   macro avg       0.52      0.89      0.50     23127\n",
      "weighted avg       0.99      0.89      0.94     23127\n",
      "\n",
      "I am for this  0.55\n",
      "[[20684  2335]\n",
      " [   13    95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     23019\n",
      "           1       0.04      0.88      0.07       108\n",
      "\n",
      "    accuracy                           0.90     23127\n",
      "   macro avg       0.52      0.89      0.51     23127\n",
      "weighted avg       0.99      0.90      0.94     23127\n",
      "\n",
      "I am for this  0.6\n",
      "[[20925  2094]\n",
      " [   13    95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     23019\n",
      "           1       0.04      0.88      0.08       108\n",
      "\n",
      "    accuracy                           0.91     23127\n",
      "   macro avg       0.52      0.89      0.52     23127\n",
      "weighted avg       0.99      0.91      0.95     23127\n",
      "\n",
      "I am for this  0.65\n",
      "[[21128  1891]\n",
      " [   15    93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     23019\n",
      "           1       0.05      0.86      0.09       108\n",
      "\n",
      "    accuracy                           0.92     23127\n",
      "   macro avg       0.52      0.89      0.52     23127\n",
      "weighted avg       0.99      0.92      0.95     23127\n",
      "\n",
      "I am for this  0.7\n",
      "[[21336  1683]\n",
      " [   20    88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     23019\n",
      "           1       0.05      0.81      0.09       108\n",
      "\n",
      "    accuracy                           0.93     23127\n",
      "   macro avg       0.52      0.87      0.53     23127\n",
      "weighted avg       0.99      0.93      0.96     23127\n",
      "\n",
      "I am for this  0.75\n",
      "[[21497  1522]\n",
      " [   21    87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97     23019\n",
      "           1       0.05      0.81      0.10       108\n",
      "\n",
      "    accuracy                           0.93     23127\n",
      "   macro avg       0.53      0.87      0.53     23127\n",
      "weighted avg       0.99      0.93      0.96     23127\n",
      "\n",
      "I am for this  0.8\n",
      "[[21650  1369]\n",
      " [   27    81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     23019\n",
      "           1       0.06      0.75      0.10       108\n",
      "\n",
      "    accuracy                           0.94     23127\n",
      "   macro avg       0.53      0.85      0.54     23127\n",
      "weighted avg       0.99      0.94      0.96     23127\n",
      "\n",
      "I am for this  0.85\n",
      "[[21780  1239]\n",
      " [   28    80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     23019\n",
      "           1       0.06      0.74      0.11       108\n",
      "\n",
      "    accuracy                           0.95     23127\n",
      "   macro avg       0.53      0.84      0.54     23127\n",
      "weighted avg       0.99      0.95      0.97     23127\n",
      "\n",
      "I am for this  0.9\n",
      "[[22047   972]\n",
      " [   61    47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     23019\n",
      "           1       0.05      0.44      0.08       108\n",
      "\n",
      "    accuracy                           0.96     23127\n",
      "   macro avg       0.52      0.70      0.53     23127\n",
      "weighted avg       0.99      0.96      0.97     23127\n",
      "\n",
      "I am for this  0.95\n",
      "[[22364   655]\n",
      " [  105     3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     23019\n",
      "           1       0.00      0.03      0.01       108\n",
      "\n",
      "    accuracy                           0.97     23127\n",
      "   macro avg       0.50      0.50      0.50     23127\n",
      "weighted avg       0.99      0.97      0.98     23127\n",
      "\n",
      "I am for this  1.0\n",
      "[[23019     0]\n",
      " [  108     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23019\n",
      "           1       0.00      0.00      0.00       108\n",
      "\n",
      "    accuracy                           1.00     23127\n",
      "   macro avg       0.50      0.50      0.50     23127\n",
      "weighted avg       0.99      1.00      0.99     23127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#trying to find the best threshold to tune\n",
    "\n",
    "threshold=[0,0.5,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]\n",
    "for num in threshold:\n",
    "    y_pred_thresh = (y_prob > num).astype(int)\n",
    "    # Re-evaluate\n",
    "    print('I am for this ', num )\n",
    "    print(confusion_matrix(y_test, y_pred_thresh))\n",
    "    print(classification_report(y_test, y_pred_thresh))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7326c2d-e82c-4ab6-932a-c2b7e8a03a86",
   "metadata": {},
   "source": [
    "Threshold    Precision (1)     Recall (1)     F1 (1)        Notes\n",
    "0.1          0.01              0.98           0.02          Very aggressive, catches all but too noisy\n",
    "0.25         0.02              0.98           0.04          Good recall, still noisy\n",
    "0.45         0.03              0.90           0.06          Balanced, better than default\n",
    "0.65         0.05              0.86           0.09          Best tradeoff so far\n",
    "0.85         0.06              0.74           0.11          More precise, but fewer true returns\n",
    "0.95         0.00              0.03           0.01          Too harsh, misses most returns\n",
    "\n",
    "#so finalising the threshold as 0.65"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6de47983-fdd2-46ca-87b8-7ef5314f56cf",
   "metadata": {},
   "source": [
    "#Other ways to tune the model\n",
    "Tuning Method              What It Does                                      When to Use\n",
    "Threshold tuning           Adjusts balance of precision vs recall            FIRST thing to do for imbalanced data\n",
    "Hyperparameter tuning      GridSearchCV on C, penalty, etc.                  Try if model underfits or overfits\n",
    "Try different models       RandomForest, XGBoost, etc.                       When logistic regression lacks complexity\n",
    "Feature engineering        Add interaction terms, ratios, domain logic       To boost signal and context\n",
    "Feature selection          Drop noisy or uninformative features              When precision/recall don’t improve\n",
    "Resampling techniques      SMOTE, undersampling, oversampling                Try if recall is low or classes too skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd5b361-3af8-465c-8dbd-837404a68b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.65\n",
    "y_pred_final = (y_prob > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb98ce5-c0b0-4097-8d6f-a4b72ca68367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.046875 \n",
      " recall : 0.8611111111111112 \n",
      " f1_score : 0.08891013384321224 \n",
      " roc-auc: 0.9277923390178484 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extracting final metrics\n",
    "\n",
    "precision = precision_score(y_test, y_pred_final)\n",
    "recall = recall_score(y_test, y_pred_final)\n",
    "f1 = f1_score(y_test, y_pred_final)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print('precision :',precision,'\\n','recall :',recall,'\\n','f1_score :',f1,'\\n','roc-auc:',roc_auc,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8e4fc8a-ca38-400c-9550-991f429e9ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training RandomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/base.py:1363: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results for RandomForest at threshold = 0.65\n",
      "[[23013     6]\n",
      " [   86    22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23019\n",
      "           1       0.79      0.20      0.32       108\n",
      "\n",
      "    accuracy                           1.00     23127\n",
      "   macro avg       0.89      0.60      0.66     23127\n",
      "weighted avg       1.00      1.00      0.99     23127\n",
      "\n",
      "ROC AUC Score: 0.9342469505867135\n",
      "\n",
      " Training XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [22:12:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results for XGBoost at threshold = 0.65\n",
      "[[22843   176]\n",
      " [   32    76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     23019\n",
      "           1       0.30      0.70      0.42       108\n",
      "\n",
      "    accuracy                           0.99     23127\n",
      "   macro avg       0.65      0.85      0.71     23127\n",
      "weighted avg       1.00      0.99      0.99     23127\n",
      "\n",
      "ROC AUC Score: 0.9909507122135819\n",
      "\n",
      " Training LightGBM\n",
      "[LightGBM] [Info] Number of positive: 430, number of negative: 92076\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 92506, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004648 -> initscore=-5.366584\n",
      "[LightGBM] [Info] Start training from score -5.366584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/lakshmiprasannapoluru/Desktop/smart-return-predictor/venv/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      " Results for LightGBM at threshold = 0.65\n",
      "[[19992  3027]\n",
      " [   23    85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93     23019\n",
      "           1       0.03      0.79      0.05       108\n",
      "\n",
      "    accuracy                           0.87     23127\n",
      "   macro avg       0.51      0.83      0.49     23127\n",
      "weighted avg       0.99      0.87      0.93     23127\n",
      "\n",
      "ROC AUC Score: 0.8273706664221023\n"
     ]
    }
   ],
   "source": [
    "#Trying RF, XGBoost, LGB models\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(scale_pos_weight=100, use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(scale_pos_weight=100, random_state=42)\n",
    "}\n",
    "\n",
    "#Added scale_pos_weight as classes are highly imbalanced\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    threshold = 0.65  # Based on your earlier tuning\n",
    "    y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n Results for {name} at threshold = {threshold}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc78c9dd-4d68-490d-808d-17c39a47d401",
   "metadata": {},
   "source": [
    "Model           Precision     Recall    F1-Score    ROC AUC     Comment\n",
    "Logistic Reg.   0.05          0.86      0.09        0.927       Weak precision but high recall\n",
    "Random Forest   0.79          0.20      0.32        0.934       Great precision, poor recall\n",
    "XGBoost         0.30          0.70      0.42        0.991       Best balance overall\n",
    "LightGBM        0.03          0.79      0.05        0.827       Poor precision, high recall, but overall weaker\n",
    "\n",
    "Best Model: XGBoost\n",
    "\t- High Recall (0.70): Captures many of the actual returns\n",
    "\t- Better Precision than Logistic or LightGBM\n",
    "\t- Best ROC AUC (0.99): Excellent model confidence separation\n",
    "\n",
    "              Predicted\n",
    "             0       1\n",
    "Actual 0   [TN      FP]  \n",
    "Actual 1   [FN      TP] \n",
    "\n",
    "TP (True Positives): Predicted return and it was returned ✅\n",
    "\t•\tFN (False Negatives): Missed a return ❌\n",
    "\t•\tFP (False Positives): Flagged return that wasn’t ❌\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cca445f4-f65f-4f63-9be5-c7665140292e",
   "metadata": {},
   "source": [
    "Push performance before logging in MLflow:\n",
    "\n",
    "1. Hyperparameter Tuning\n",
    "Use:\n",
    "\t- GridSearchCV or RandomizedSearchCV (sklearn)\n",
    "\t- or optuna (for smart automated tuning)\n",
    "\t- Focus on tuning max_depth, n_estimators, learning_rate, scale_pos_weight\n",
    "\n",
    "2. Feature Engineering\n",
    "\t- Try interaction terms or binned features (like bucket delivery_delay)\n",
    "\t- Try dropping correlated or redundant features\n",
    "\n",
    "3. Resampling\n",
    "\t- Try SMOTE, RandomOverSampler, or ClassWeight tuning to handle imbalance\n",
    "\n",
    "4. Stacking/Ensemble\n",
    "\t- Combine Logistic + XGBoost for a stacking classifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81876b91-cfa5-46be-9d3f-fd13e16b1514",
   "metadata": {},
   "source": [
    "🔹 Step 5: Log with MLflow\n",
    "\n",
    "✅ Goal:\n",
    "\n",
    "Track everything: model, hyperparameters, metrics, version\n",
    "\n",
    "Before this, install MLflow if you haven’t already:\n",
    "\n",
    "pip install mlflow\n",
    "\n",
    "📍 Minimal MLflow Logging:\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, y_prob))\n",
    "    mlflow.sklearn.log_model(model, \"logistic_model\")\n",
    "    print(\"Run logged to MLflow.\")\n",
    "\n",
    "Then run:\n",
    "mlflow ui\n",
    "\n",
    "Open browser at: http://localhost:5000 to view your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d65cb-9f39-439c-90e2-fcec2fa01f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
